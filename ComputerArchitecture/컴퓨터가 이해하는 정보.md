# 컴퓨터가 이해하는 정보

## 비트, 워드, 단위

### 비트

- CPU는 기본적으로 0과 1만 이해할 수 있다.
    - `비트` : 0과 1을 나타내는 `가장 작은 정보 단위`
        - 1 bit : 0,1 - 2개
        - 2 bit : 00,01,10,11 - 4개
        - 즉, n bit는 $2^n$개 만큼 표현 가능하다.

### 단위
- Byte,KB,MB,GB,TB : 단위
    - 1 Byte : 8 bit
    - 1 KB : 1000 Byte 
    - 1 MB : 1000 KB
    - 1 GB : 1000 MB
    - 1 TB : 1000 GB
    - 1000대신 `1024`개씩 묶은 것 -> i를 중간에 넣어 KiB,MiB,GiB,TiB로 표현한다.
### 워드
- `워드` : `CPU`가 `한 번에 처리`할 수 있는 `데이터의 크기`
    - CPU는 프로그램을 `워드` 단위로 읽어 들이고, 처리한다.
    - 예시
        - CPU가 한 번에 32bit 처리 가능
            - 워드 크기 : 32bit
    - 현대 컴퓨터의 워드 크기는 대부분 32bit, 64bit

## 소수
- 핵심 : `표현하고자 하는 소수`와 `저장된 소수`간에 `오차`가 있을 수 있다.
    - Y? `부동 소수점` 표현 방식에 `정밀도의 한계`가 존재하기 때문

### 부동 소수점
- 소수점이 고정되어 있지 않은 소수 표현 방식
    - 필요에 따라 `소수점의 위치가 이동할 수 있고`, `유동적`이다.
- 2진수 체계에서 소수점은 다음과 같이 나타낸다.
    - $m*2^n$
        - m : 가수, n : 지수
        - 지수가 양수 : 소수점을 왼쪽으로 이동한 횟수
        - 지수가 음수 : 소수점을 오른쪽으로 이동한 횟수
- `IEEE 754` : 오늘날 대부분의 컴퓨터가 2진수의 지수와 가수를 저장하는 형식
    - ![IEEE754 이미지](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSI3zZiY_4CrOPv8MmpF91wKTch65jmJk0Edg&s)
        - 위: 32bit, 아래 : 64bit 
        - sign : 부호비트
        - exponent : 지수 비트
        - fraction : 소수 비트
    - 이때, fraction의 정수부에는 1로 통일화된 `정규화한 수`가 저장된다.
        - 즉, 가수(m)가 1.xxxxxx의 형태를 띄고있다.
        - 따라서, 지수와 xxxxxx만 저장하면 된다. 이것이 `exponent`와 `fraction`이다.
            - 지수를 저장할 때는 bias 값이 더해져서 저장된다.
                - 지수가 음수가 될 때도 있다. 이때, 항상 `양수로 저장`하기 위해서 bias를 더한다.
                - 이때, 더하는 bias는 $2^{k-1}-1$이다.
                    - ex, 8bit로 표현한다면, 더하는 bias는 $2^7-1 = 127$이다.
- 주의, 10진수 소수를 2진수로 표현할 때, 10진수 소수와 2진수 소수의 표현이 딱 맞지 않을 수 있다. 
    - 이것이 위에서 말한 오차의 원인이다.
    - ex, 0.1은 10진수 소수에서 $1*10^-1$ 이지만, 2진수로는 무한하다. 
        - 따라서, `2진수로 저장` 시 `일부 소수점이 생략`되고, 여기에서 `오차가 발생`한다.

## 문자 집합
> 컴퓨터가 이해할 수 있는 `문자들의 집합`

### 문자 인코딩 
- `문자 집합`에 속한 문자를 `컴퓨터가 이해하는 0과 1`로 이루어진 `문자 코드로 변환`하는 과정

    - `동일한 문자 집합`이더라도, `다양한 문자 인코딩 방법이 존재`할 수 있다.

### 문자 디코딩
- 문자 인코딩의 반대, `0과 1로 표현된 문자 코드`를 `사람이 이해하는 문자`로 `변환`


### ASCII 문자집합
- 가장 기본적인 문자 집합
    - 알파벳, 아라비아 숫자, 일부 특수 문자 포함
- 8bit 문자 집합
    - `1 bit`는 `parity bit`로 `오류 검출`에 이용
    - 따라서, `문자를 표현하는 bit`는 `7bit` = `128`개 표현

### EUC-KR 인코딩
- 한글 인코딩 방식 중 하나.
    - `KS X 1001`, `KS X 1003` 문자 집합 기반의 인코딩 방식
    - ASCII 문자 표현할 땐, 1 바이트, 한글 1글자를 표현할 땐 2바이트 크기의 코드를 부여한다.
        - 2Byte = 16bit = 4자리 16진수 | 한글 1글자를 4자리 16진수로 표현할 수 있다.
### 유니코드 문자집합
- 한글을 포함해 훨씬 많은 언어, 특수문자, 화살표, 이모티콘까지 코드로 표현할 수 있는 `통일된 문자 집합`
- 현대에서 `가장 많이 사용`되는 `표준 문자 집합`

- 글자에 부여된 값 자체를 `인코딩된 값`으로 삼지 않고, `다양한 방법`으로 `인코딩`
    - 방식 : UTF-8,UTF-16,UTF-32
        - 가변 길이 인코딩 : UTF-8, UTF-16
            - 인코딩된 결과의 길이가 `일정하지 않을 수 있음`
        - 고정 길이 인코딩 : UTF-32
            - `일정함`
### base64 인코딩
- 64진법 사용
    - $64=2^6$, 즉 6bit 씩 변환
        - 기본적으로 4개씩 한 번에 변환된다. (24bit)
        - ex, abc = 01100001,01100010,01100011(ASCII)
            - 이를 아래와 같이 나누어 Base64 인코딩할 수 있다.
                - 011000 : Y(base64 변환)
                - 010110 : W
                - 001001 : J
                - 100011 : j
                - 즉 ASCII abc == base64 YWJj 이다.
        - 만약 24bit씩 하는데, 나누어 떨어지지 않는다면, 0으로 채워지는 패딩 진행
- `이진 데이터`까지 `변환`할 수 있는 인코딩 방식
    - 문자보다 `이진 데이터 변환`에 `주로 이용`
        - `이미지, 동영상` 등 `문자 이외의 데이터`까지 모두 `아스키 문자 형태`로 표현할 수 있다.
